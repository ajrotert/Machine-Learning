{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BookGen.ipynb",
      "provenance": [],
      "mount_file_id": "1PBFHTFgzza9a5Ry2-6QI9JMsYrkovicA",
      "authorship_tag": "ABX9TyPDzLMP2d6BSCzVuACp5biu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajrotert/Machine-Learning/blob/master/BookGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWc9lBwNIp4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ttfcye78I1qB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/Data/HungerGames.txt') as stream:\n",
        "  text = stream.read()\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "char_indices = dict((c,i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i,c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vStHnWuOMSd_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "8ca76f99-536f-4b71-a5a5-323eb04c8195"
      },
      "source": [
        "print(text[:500])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ï»¿The Hunger Games\n",
            "\n",
            "\n",
            "The Hunger Games 1by Suzanne Collins\n",
            "\n",
            "PART I\"THE TRIBUTES\"\n",
            "\n",
            "1.\n",
            "\n",
            "When I wake up, the other side of the bed is cold. My fingers stretch out, seeking Prims warmth but finding only the rough canvas cover of the mattress. She must have had bad dreams and climbed in with our mother. Of course, she did. This is the day of the reaping. I prop myself up on one elbow. Theres enough light in the bedroom to see them. My little sister, Prim, curled up on her side, cocooned in my mothers b\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_I1kMKtMak6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "695166d9-50b7-487b-9acb-814d901113ee"
      },
      "source": [
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_char = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "  sentences.append(text[i: i+maxlen])\n",
        "  next_char.append(text[i+maxlen])\n",
        "print(len(sentences))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "173964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAoloEldNZTn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4e59313c-1d80-4c85-cdf5-e8387f71d7fb"
      },
      "source": [
        "print(sentences[0:20])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\ufeffThe Hunger Games\\n\\n\\nThe Hunger Games 1by', 'e Hunger Games\\n\\n\\nThe Hunger Games 1by Su', 'unger Games\\n\\n\\nThe Hunger Games 1by Suzan', 'er Games\\n\\n\\nThe Hunger Games 1by Suzanne ', 'Games\\n\\n\\nThe Hunger Games 1by Suzanne Col', 'es\\n\\n\\nThe Hunger Games 1by Suzanne Collin', '\\n\\nThe Hunger Games 1by Suzanne Collins\\n\\n', 'he Hunger Games 1by Suzanne Collins\\n\\nPAR', 'Hunger Games 1by Suzanne Collins\\n\\nPART I', 'ger Games 1by Suzanne Collins\\n\\nPART I\"TH', ' Games 1by Suzanne Collins\\n\\nPART I\"THE T', 'mes 1by Suzanne Collins\\n\\nPART I\"THE TRIB', ' 1by Suzanne Collins\\n\\nPART I\"THE TRIBUTE', 'y Suzanne Collins\\n\\nPART I\"THE TRIBUTES\"\\n', 'uzanne Collins\\n\\nPART I\"THE TRIBUTES\"\\n\\n1.', 'nne Collins\\n\\nPART I\"THE TRIBUTES\"\\n\\n1.\\n\\nW', ' Collins\\n\\nPART I\"THE TRIBUTES\"\\n\\n1.\\n\\nWhen', 'llins\\n\\nPART I\"THE TRIBUTES\"\\n\\n1.\\n\\nWhen I ', 'ns\\n\\nPART I\"THE TRIBUTES\"\\n\\n1.\\n\\nWhen I wak', '\\nPART I\"THE TRIBUTES\"\\n\\n1.\\n\\nWhen I wake u']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4LHgqiqNhAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, char in enumerate(sentence):\n",
        "    x[i,t,char_indices[char]] = 1\n",
        "  y[i,char_indices[next_char[i]]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucYWkrzJO3zg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7oFZG4HO8o7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "ad520a8c-cf89-422d-e73e-7f94d84f03ba"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "callbacks = [EarlyStopping(monitor=\"loss\", patience=2), ModelCheckpoint(filepath=\"bestmodel.h5\", monitor=\"loss\", save_best_only=True)]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 128)               104448    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 75)                9675      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 75)                0         \n",
            "=================================================================\n",
            "Total params: 114,123\n",
            "Trainable params: 114,123\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxaAmpfiQWx5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "83431c18-cbed-46a5-f249-b6702b756266"
      },
      "source": [
        "epochs = 30\n",
        "batch_size = 128\n",
        "model.fit(x, y, batch_size=batch_size, epochs=epochs, callbacks=callbacks)\n",
        "model.save_weights('/content/drive/My Drive/Data/lstm_weights.h5')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1360/1360 [==============================] - 160s 117ms/step - loss: 1.9465\n",
            "Epoch 2/30\n",
            "1360/1360 [==============================] - 161s 118ms/step - loss: 1.5978\n",
            "Epoch 3/30\n",
            "1360/1360 [==============================] - 161s 118ms/step - loss: 1.5018\n",
            "Epoch 4/30\n",
            "1360/1360 [==============================] - 161s 118ms/step - loss: 1.4497\n",
            "Epoch 5/30\n",
            "1360/1360 [==============================] - 161s 118ms/step - loss: 1.4169\n",
            "Epoch 6/30\n",
            "1360/1360 [==============================] - 161s 118ms/step - loss: 1.3918\n",
            "Epoch 7/30\n",
            "1360/1360 [==============================] - 161s 118ms/step - loss: 1.3732\n",
            "Epoch 8/30\n",
            "1360/1360 [==============================] - 162s 119ms/step - loss: 1.3562\n",
            "Epoch 9/30\n",
            "1360/1360 [==============================] - 161s 119ms/step - loss: 1.3432\n",
            "Epoch 10/30\n",
            "1360/1360 [==============================] - 162s 119ms/step - loss: 1.3317\n",
            "Epoch 11/30\n",
            "1360/1360 [==============================] - 163s 120ms/step - loss: 1.3217\n",
            "Epoch 12/30\n",
            "1360/1360 [==============================] - 167s 122ms/step - loss: 1.3132\n",
            "Epoch 13/30\n",
            "1360/1360 [==============================] - 162s 119ms/step - loss: 1.3032\n",
            "Epoch 14/30\n",
            "1360/1360 [==============================] - 162s 119ms/step - loss: 1.2995\n",
            "Epoch 15/30\n",
            "1360/1360 [==============================] - 162s 119ms/step - loss: 1.2924\n",
            "Epoch 16/30\n",
            "1360/1360 [==============================] - 166s 122ms/step - loss: 1.2859\n",
            "Epoch 17/30\n",
            "1360/1360 [==============================] - 162s 119ms/step - loss: 1.2812\n",
            "Epoch 18/30\n",
            "1360/1360 [==============================] - 162s 119ms/step - loss: 1.2780\n",
            "Epoch 19/30\n",
            "1360/1360 [==============================] - 162s 119ms/step - loss: 1.2732\n",
            "Epoch 20/30\n",
            "1360/1360 [==============================] - 167s 123ms/step - loss: 1.2672\n",
            "Epoch 21/30\n",
            "1360/1360 [==============================] - 163s 120ms/step - loss: 1.2645\n",
            "Epoch 22/30\n",
            "1360/1360 [==============================] - 163s 120ms/step - loss: 1.2595\n",
            "Epoch 23/30\n",
            "1360/1360 [==============================] - 164s 121ms/step - loss: 1.2573\n",
            "Epoch 24/30\n",
            "1360/1360 [==============================] - 164s 120ms/step - loss: 1.2528\n",
            "Epoch 25/30\n",
            "1360/1360 [==============================] - 166s 122ms/step - loss: 1.2514\n",
            "Epoch 26/30\n",
            "1360/1360 [==============================] - 166s 122ms/step - loss: 1.2482\n",
            "Epoch 27/30\n",
            "1360/1360 [==============================] - 166s 122ms/step - loss: 1.2444\n",
            "Epoch 28/30\n",
            "1360/1360 [==============================] - 165s 121ms/step - loss: 1.2411\n",
            "Epoch 29/30\n",
            "1360/1360 [==============================] - 163s 120ms/step - loss: 1.2364\n",
            "Epoch 30/30\n",
            "1360/1360 [==============================] - 164s 121ms/step - loss: 1.2360\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OW3midukdQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "def sample(preds, temp=1.0):\n",
        "  preds= np.asarray(preds).astype('float64')\n",
        "  preds=np.log(preds)/temp\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds= exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A_jYSfHlF3n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "1bbd2da4-5a2c-4761-e9f1-bbb030766e62"
      },
      "source": [
        "import sys\n",
        "start_index = random.randint(0,len(text) - maxlen -1)\n",
        "for diversity in [.05, .2, .5, 1.0]:\n",
        "  print()\n",
        "  print('----- diversity:', diversity)\n",
        "  generated = ''\n",
        "  sentence = text[start_index: start_index+maxlen]\n",
        "  generated += sentence\n",
        "  print('----- Generting with seed: ', sentence)\n",
        "  sys.stdout.write(generated)\n",
        "  for i in range(400):\n",
        "    x = np.zeros((1, maxlen, len(chars)))\n",
        "    for t, char in enumerate(sentence):\n",
        "      x[0,t,char_indices[char]] = 1.0\n",
        "    preds = model.predict(x, verbose=0)[0]\n",
        "    next_index = sample(preds, diversity)\n",
        "    next_char = indices_char[next_index]\n",
        "    generated += next_char\n",
        "    sentence = sentence[1:] + next_char\n",
        "    sys.stdout.write(next_char)\n",
        "    sys.stdout.flush()\n",
        "  print()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----- diversity: 0.05\n",
            "----- Generting with seed:  you make it back, will you?\n",
            "\n",
            "Count on it\n",
            "you make it back, will you?\n",
            "\n",
            "Count on it and the start of the blood and the start of the blood and the start of the blood and the start of the blood and the start of the blood and the start of the blood and the start of the blood and the start of the blood and the start of the blood and the start of the blood and the start of the stage of the blood. I see the blood. The smell of the blood. I see the blood. I see the blood. I see the blo\n",
            "\n",
            "----- diversity: 0.2\n",
            "----- Generting with seed:  you make it back, will you?\n",
            "\n",
            "Count on it\n",
            "you make it back, will you?\n",
            "\n",
            "Count on it and the worst the stage of the blood. The sky on the woods and the blood and the ground the woods and the start of blood. I want to the boy from District 11"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ". The course of the stream and the boy from District 11 I see the back of the blood. I see the woods are the stage and the reaping of blood. The boy from District 11. The slidies to the door. I see the stage and the blood and so the blood and \n",
            "\n",
            "----- diversity: 0.5\n",
            "----- Generting with seed:  you make it back, will you?\n",
            "\n",
            "Count on it\n",
            "you make it back, will you?\n",
            "\n",
            "Count on it. As I start the blood. I see its at a station. She should while I cant see the woods were not that I can feel the peecial and when I reach to the last of call my strange who catch the love pressimary. I so the other does. I reach the sense he says with the sense the breal. I see I cant start the woods take still screaminated the looker and this doesnt really another a botteam with the breakfast a\n",
            "\n",
            "----- diversity: 1.0\n",
            "----- Generting with seed:  you make it back, will you?\n",
            "\n",
            "Count on it\n",
            "you make it back, will you?\n",
            "\n",
            "Count on its coal clear. I dont put the conversar comelifion. In the screen of intouray minect, and we can feel him. What, commintarge in trees pair pit at him enough, hes sliding on the deep her hand clothing through the roof of infering markets. The word districts are to somewhingers what wells an arrow you have shovay knew looks me cold? I ask. A actian interviewing we will be hil night an the timible of \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}